\subsection{Schema change extraction}
\label{subsec:schema-change-extraction}
% \paragraph{\textbf{Schema extraction}}
Different from previous work~\cite{wang2019synthesizing} that identifies schema changes by comparing the old and the new schemas written in SQL,
\Tool takes the unique opportunity offered by
web applications and identifies schema changes directly from all the new migration
files in the new version.
%offer the unique opportunity to extract schema changes directly from migration files, where schema changes
% are explicitly listed in order. 
%  The migration file works as a `diff' to the schema file. In one commit, developers can write as many as migration files to change their schema.  

% Taking this unique opportunity, \Tool{} analyzes newly added migration files between two versions one by one.
Specifically, 12 out of 19 Rails migration APIs and 6 out of 17 Django
migration APIs introduce schema changes that can immediately cause code inconsistency.
 \Tool{} matches each such API, or an API--parameter combination in case of Django, with one change type listed
 in Table \ref{tab:overview}. Whenever such an API call
 is identified in a migration file, \Tool{} extracts
 related change information, like table and column
 names, and saves it as a change
 record for later use.
 %Note that, one migration API call may introduce more
 %than one change record, like multiple columns getting
 %deleted using one \texttt{remove\_column} API call.
 %into a hash table for later use. In this hash table, the key represents the change type, and the value represents the previous and current schema.  
 %For example, line 5 in Listing~\ref{onebody-query} is extracted as  (Person.sequence, ``column\_rename'', Person.position). 
 \Tool aggregates related changes to the
 same target:  
deleting a column and then adding it back to the same table will be aggregated
and correctly considered as no change.
 

 %\shan{is there a special migration file for Django application? how exactly do you extract the scheme? do you use an existing framework to extract abstract syntax tree (AST) or something? in what form is the extracted schema represented for your later cross-version comparison? you may want to show an example} 
%  construct the enhanced schema \shan{what does enhanced mean?} from the abstract syntax tree (AST) generated by existing parser (yard for Rails applications, and pyparser for Django applications). The enhanced schema not only contains the tables and columns information but also preserves all the history information such as whether the current column is renamed from a previous column\shan{``all'' the history information sounds like you track all the changes since the 
%  creation of a table. I guess that is not the case? Does each version has its own migration file?
%  Or does every pair of code versions contain one migration file? Readers need some background
%  here.}. \Tool will also go through all the model class files \shan{what is the relationship
%  between these files and schema files?} to map the model classes to the tables. The mapping is built upon string transformation, for example, the \texttt{User} class maps to \texttt{users} table. 

Finally, in Rails, since an association relationship
is defined 
%partly through migration files  and 
partly through 
model classes, \Tool compares model class definitions, in addition to migration files, to get association changes. For example, the model class definitions in Listing \ref{association}
uses \texttt{has\_many} to indicate that each \texttt{User} record
is related to multiple \texttt{Comment} records, which can be retrieved through the association field \texttt{comments} defined in  \texttt{User}.

%\junwen{Also, for an association, such as one to many relation between \texttt{User} class and \texttt{Comment} class,  the foreign key \texttt{user\_id} is declared in migration files but the association type (has\_many/belongs\_to) and name (comments/user) is stored in the model class as shown in  Listing~\ref{association}.} 
%  \shan{?? what does this mean?}. The association type and association name are declared in the model class files as shown in Listing~\ref{associationfile}. So \Tool will analyze the association definition function such as \texttt{has\_many} in Rails (ForeignKey in Django) to extract association information.
%  \shan{you also mentioned index changes earlier. Do you identify that information here?}
%  \shan{It is not clear to me whether you try to extract all data schemas here, or you just
%  try to identify all the changed schema, and it is not clear whether you are just analyzing
%  one version of the software or both the old and the new versions.
%  This became clear after I read the next paragraph, but it should have been made clear
%  earlier.}
 
 
%  \paragraph{\textbf{Change extraction}}
%  By comparing the enhanced schema across two versions, \Tool{} is able to extract the schema change described in Section~\ref{change} into a hash table, where the key represents the change type, and the value represents the previous and current schema.  For example, the rename in line 1 in Listing~\ref{onebody-query} will be represented as \{``column\_rename'' : (Person.sequence, Person.position)\}. 
 
%  \shan{doesn't migration file like the one in Listing 1 already tell you what is been changed?
%  why do you need to compare schemas from two versions to know that?} \junwen{Ideally yes, but it's possible the migration file itself will be changed by developers.}
 
%\Tool{} first extracts the schema of the previous version of the application, and then extracts the schema of the current version of the application. Then, \Tool{} extracts the difference between the two schemas, where that schema difference is then compared with the queries in the current application to find any inconsistencies.

% \lstinputlisting[label={migrationfile}, caption={Migration file from Lobsters},language=Ruby]{migration.rb}


\subsection{Query extraction}
Next, \Tool identifies all the queries that can be
issued by the new version of the application.
%, together with source-code location,
%the table, column, association, and index information for each query if applicable.
%extraction takes the application's source code as the input and returns a set of code snippets that will issue queries and the corresponding tables, columns, associations, indices used as well as the location including filename, line of code, start offset, and length.
In ORM, a query can be expressed in two forms: 1) an ORM query API such as
\texttt{find\_by} in Rails and \texttt{filter} in Django invoked upon either
an object holding a previous query's result
or a model class like that in
line 1 of Listing~\ref{queries};
2) the reference to a model class' association field. For example, 
following the association definition in Listing \ref{association}, \texttt{@user.comments} in Listing \ref{queries}
issues a query to select records from table 
\texttt{comments} as `select * from comments where user\_id = user.id'. 
%an unchained one or chained one
%The query extraction will identify (1) unchained queries which are statements that start with model class name such as \texttt{User} and follow by query keywords such as line 1 in  Listing~\ref{queries}  (2) chained queries which are statements that start with variables which are query result and follow by query keywords such as line 2 in Listing~\ref{queries}. 

%There are two types of query keywords for a variable 

% (2) the association of the variable's class e.g., 
%, where  the class of @user and the class of comments are associated model classes.    

\Tool identifies both forms of queries
and extracts the names
of table, column, index, and related association information from each query. The analysis for Django applications is done by
analyzing the AST generated by pyast. 
The analysis
for Rails applications is 
built upon ORM-aware static analysis framework  PowerStation~\cite{yang2018powerstation}. 
%Also, it has a set of Django query API manually extracted from Django documents as part of the query keywords. 
%To identify chained queries (i.e., the query
%API or the association field is upon an object holding
%results from a previous query), 
\Tool uses intra-procedural dependency analysis to identify objects that hold results from a previous query.
In theory, it may miss queries on objects defined
in a different procedure.%, which is very rare in web applications.


\lstinputlisting[
float=t,
basicstyle=\footnotesize\ttfamily\color{black},
label={association}, 
caption={Association-Field Definition and Changes in Onebody},
language=Ruby]{association.rb}

\lstinputlisting[float=t,label={queries}, caption={Two types of statements that issue SQL queries},language=Ruby]{evolutionsaver/query.rb}

% \paragraph{\textbf{Extracting unchained queries}} \Tool starts the extraction from unchained queries, which are statements that start with model class name such as \texttt{User} and follows by query keywords such as \texttt{find\_by} in Rails, \texttt{filter} in Django. To identify the unchained query, \Tool will examine each function call node from the AST, and check whether the caller matches any model class name extracted in Section~\ref{subsec:schema-change-extraction} and the function name matches any query keywords\shan{how many keywords are there? how do you get
% a complete list of these keywords? are they complete? could there be false positives or negatives?}. If so, the node will be considered as an unchained query, and the variable it defines (@user in listing~\ref{queries}) will be kept for later usage including the name of the variable, and the table it queries on.

% \paragraph{\textbf{Extracting chained queries}} After getting a list of variables 
% \shan{1. what if this variable's value is assigned to another variable and then
% chained queries are issued on that variables? 2. is there any alias issue for variables?
% do you do these searches within one function? within one file?}
% defined by the unchained queries, denoted as query results, \Tool then still analyze all the function call nodes to see whether the caller is a variable from the query results, if so we will check the function name. Different from unchained queries,  the function name could be a query keyword, a column name of the model class, or an association of the model class. As shown in line 2 in  Listing~\ref{queries}, \texttt{comments} is an association of \texttt{User} class. \shan{why do you not need to worry about these for unchained queries?}\shan{do you keep looking for such chained queries or do you have a threshold
% of certain number of chains to check?}
% \shan{please comment on how common are chained queries}


% \paragraph{\textbf{Extracting tables, columns, associations in a query}}
% Besides the table name extracted from unchained queries, and the column name and association name extracted from the chained queries. We still need to analyze the parameters of the query functions to extract further information. For most of the query functions, the parameters are the column names of the queried tables, such as \texttt{name:?} in line in in Listing~\ref{queries}. It's also possible to use the associations as the parameter of query function such as \texttt{@user.includes(:comments)}. \Tool will extract the columns and associations used in the parameters for different query functions. 

% \shan{this paragraph is too long. you probably want to split the discussion about extracting non-chained queries from that about extracting chained queries.}
% \Tool{} extracts intraprocedural chained and unchained queries, as well as WRITE and READ queries. READ queries can be both chained and unchained. WRITE queries can only be unchained because WRITE queries do not return a QuerySet that can be further queried. Extracting WRITE queries is a very different process than extracting READ queries, as both the function and format of a WRITE and READ query are different. \Tool{} uses the python module AST to extract the table and/or column(s) that a specific WRITE query or unchained READ query refers to\shan{how do you know what statements are queries? is there a list of APIs that are read and a list of APIs that are read?}
% \shan{several topics are mixed here: (1) extracting queries; (2) extacting chained queries; (3) extracting table and column related to a query. you may want to split them to different paragraphs with each paragraph holding just one topic.}.\shan{you didn't identify association and index. should you mention that? Maybe you should organize all these by saying you will explain how to extract query statement and then explain how to identify key components of a query, including table name, column name, association, and index that are subject to potential inconsistencies.}\shan{an example can help.} The tables and columns are saved in a separate file. For chained queries, \Tool{} uses a variable system because initially for chained queries an unchained query is assigned to a variable. This variable is saved with the table that its assigned unchained query refers to in a separate file. When \Tool{} finds chained READ queries, queries in the format variable.method(column=value), \Tool{} goes through the saved variables and extracts the table and/or column(s) the query refers to and saves that information in a separate file. Another aspect to extracting queries is the case of extracting chaining queries where a query takes the “initial QuerySet of all entries in the database” [cite, not sure how?] applies a QuerySet method to that QuerySet, which returns another QuerySet, and then to that QuerySet another QuerySet method is applied. For example a chaining query could be in the format of Table.objects.filter(column=value).exclude(column=value). With chaining queries \Tool{} has to, like with chained queries, save the table to which the first method applies to, and, then, when \Tool{} recursively goes through the chaining query, \Tool{} finds the last saved table and that last saved table is the table to which the later QuerySet methods refer. Some lines of code are identified as WRITE or READ queries even if they are not. However, the extra “queries” counted do not matter, as all the WRITE and READ queries in the application are counted, and queries that improperly refer to a table or column in the schema are identified. Once \Tool{} saves all the query information in a separate file, \Tool{} sees if any of those queries are inconsistent with the new schema changes. \Tool{} also notifies if a query benefits from an added index, or if it does not benefit anymore from an index that has been deleted. 


\subsection{Inconsistency detection and refactoring suggestion}  
Finally, 
\Tool{} goes through each schema change, searches for inconsistency with
 queries in the new version, and generates refactoring suggestion accordingly
 (Table \ref{tab:overview}).

%And then we check whether the involved tables, columns, associations exist in the changed schema hash table. If we find a match, then we consider the application code needs to be refactored. If the columns referenced by a query match to a deleted indices, we consider the query might slow down. 

%\shan{I still don't get what exactly is the difference between what you are doing for renaming and traditional class/field name change refactoring. I can see that you definitely need an ORM-specific way to detect the name change. However, once you know that a class/field name should be changed, can you tell me what exactly is different from a traditional refactoring? 
% \url{https://www.jetbrains.com/help/idea/rename-refactorings.html\#rename_class_example},
% \url{https://docs.microsoft.com/en-us/visualstudio/ide/class-designer/refactoring-classes-and-types?view=vs-2019}}

\textbf{Name changes.} 
For the renaming of a table, \Tool{} checks if 
the old name \texttt{T}$_{{old}}$ is used in queries
from the new version\footnote{\Tool would issue false positives if 
\texttt{T}$_{old}$ is used to name another
table, which we have never observed.}; for the renaming of a column 
(e.g., Line 4 in Listing \ref{migration})
or an 
association field (e.g., Listing \ref{association}) \texttt{C}$_{{old}}$ in
a table \texttt{T}, \Tool checks if any new version's query refers to  
\texttt{C}$_{{old}}$ in \texttt{T}. Any such inconsistency is reported and
\Tool suggests the refactoring to replace the old name with the new name in
corresponding queries.
 
\input{evolutionsaver/handledchanges_tab}


\textbf{Deletion.} 
When a table \texttt{T}$_{old}$ is deleted, 
\Tool checks if  \texttt{T}$_{old}$ is still used in any query. If so, the query is 
reported as an error, with all the
statements in the same procedure that have control or data dependency on it 
highlighted. Since a table deletion is typically followed by major 
functionality changes, no refactoring attempt is made here. %\junwen{Posthog-3061~\cite{posthog-3061} is one pull request accepted by developers.}


When a column or association \texttt{C} in a table \texttt{T} is deleted, 
\Tool{} identifies any query that refers to \texttt{C} in \texttt{T} as an error.
In its refactoring attempt, \Tool removes \texttt{C} from
the query and runs the parser to see if the resulting query is valid.
If valid, a refactoring suggestion is made; otherwise, \Tool
reports this error without refactoring suggestion.  
%\junwen{Zulip-16975~\cite{zulip-16975} is one pull request for column deletion accepted by developers.}
%will first remove the corresponding references in the statement and assess whether it's still valid by checking whether it can be parsed by the parser. If it can, then we remove the reference to the column, if not we will mark the whole statement to be invalid and warn the users. 
For example, if column \texttt{name} is deleted from table \texttt{users}, \Tool would
suggest changing \texttt{User.find\_by(name: ?, id: ?)} to \texttt{User.find\_by(id: ?)}.
%, which is still valid. But if we then remove \texttt{id}, the statement becomes invalid. }
%\junwen{This type of code could exist in released version, and is detected by us such as https://github.com/mirumee/saleor/pull/6997.}

When an index for column \texttt{C} is deleted, 
\Tool identifies any query that conducts filtering on \texttt{C} and issues a
warning that the query may become slower.


\textbf{Type changes.}
When a \texttt{has\_one} association is changed to \texttt{has\_many}, 
the corresponding association field usually gets renamed
(from singular to plural),
and
the results of a query that refers to this association field
change from one record to an array of records (vice versa). \Tool{} conducts
the association name-change refactoring and warns users that related queries'
return type has changed, which requires further refactoring.
For column type changes, users are warned of any query that refers to a column whose type has changed. 
% \Tool{} identifies the inconsistencies among the queries made in an application and the application's schema. These inconsistencies include a query referencing a deleted or renamed table, a deleted or renamed column, a deleted or renamed association relationship, or an association relationship that has changed or an association relationship where the type has changed (e.g. a relationship that has changed from a ForeignKey relationship to a ManyToMany relationship). In addition to the inconsistencies found, \Tool{} identifies queries that benefit from recently added indexes, or queries that do not benefit anymore from recently deleted indexes.
% \shan{what exactly is your algorithm? do you identify which table name has been changed, and then identify all the queries in the old version that refer to that table, and then check the later version? Overall, the algorithm description is a bit vague.}
